import pandas as pd
import re


rule decompress_assemblies:
    input:
        "assembly_gz/genomes/{sample}_genomic.fna.gz",
    output:
        temp("assembly_gz/genomes/{sample}.fna"),
    shell:
        "zcat {input[0]} > {output[0]}"


rule print_primers_to_files:
    output:
        "InSilico/PCR/Primers.fasta",
    params:
        FW_PRIMER,
        RV_PRIMER,
    shell:
        """
        printf \
        ">primer|F \n{params[0]} \n>primer|R \n{params[1]}" >> {output}
        """


rule Extract_amplicon:
    container:
        singularity_envs["simulatePCR"]
    input:
        "InSilico/PCR/Primers.fasta",
        "assembly_gz/genomes/{sample}.fna",
    output:
        "InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons.fasta",
        temp("InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.blastout"),
    params:
        min_length=MINLEN,
        max_length=MAXLEN,
        mismatch=config["mismatch"],
        threeprime=config["threeprime"],
    log:
        dir.logs
        + "/"
        + "InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons.log",
    threads: 1
    shell:
        """
        cd $(dirname {output[0]}) && \
        simulate_PCR \
            -primers ../../../{input[0]} \
            -db ../../../{input[1]} \
            -minlen {params.min_length} \
            -maxlen {params.max_length} \
            -mm {params.mismatch} \
            -3prime {params.threeprime} \
            -mux 0 \
            -num_threads {threads} \
            -max_target_seqs 1000000000 \
            -word_size 4 \
            -evalue 100000000 \
            -genes 1 \
            -extract_amp 1 \
            >> ../../../{log}

          """


## Some sequences are extracted as reverse-complemented. Two be sure to have them in the right direction, we add reverse complemented version to each fasta. Then, the next step with cutadapt w
rule reverse_complement:
    conda:
        os.path.join(dir.envs, "amplicons_r_utils.yml")
    container:
        singularity_envs["r_utils"]
    input:
        simple_fasta="InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons.fasta",
    output:
        fasta_with_rev="InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons_complemented.fasta",
    log:
        dir.logs
        + "/"
        + "InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons_complemented.txt",
    threads: 1
    script:
        "scripts/reverse_complement.R"


rule cutadapt_trim_in_silico:
    conda:
        os.path.join(dir.envs, "cutadapt.yml")
    container:
        singularity_envs["cutadapt"]
    input:
        R1_raw_reads="InSilico/PCR/{sample}/Primers.fasta.pair.{sample}.fna.amplicons_complemented.fasta",
    output:
        R1_trimmed_reads=temp("InSilico/1a_trimmed_primers/{sample}_trimmed.fasta"),
    log:
        dir.logs + "/" + "InSilico/1a_trimmed_primers/{sample}_trimmed.txt",
    params:
        forward_primer=FW_PRIMER,
        reverse_primer=RV_PRIMER,
        excepted_errors=config["excepted_errors"],
        min_length=MINLEN,
        max_length=MAXLEN,
        coverage=config["amplicon_min_coverage"],
    threads: 1
    script:
        "../DB_processing/scripts/cutadapt_DB.py"


def list_amplicons(wildcards):
    checkpoint_output = checkpoints.download_assemblies.get(**wildcards).output[0]
    directory = "/".join((checkpoint_output.split("/")[0:2]))
    assemblynames = glob_wildcards(os.path.join(directory, "{i}_genomic.fna.gz")).i
    expd = expand(
        "InSilico/1a_trimmed_primers/{sample}_trimmed.fasta", sample=assemblynames
    )
    return expd


# primer enlever


### Combine all extracted sequences in one big fasta
rule Insilico_merge_all_in_one_fasta:
    input:
        list_amplicons,
    output:
        temp("InSilico/1c_derep/merged_all.fasta"),
    shell:
        """
        cat {input} >> {output}
        """


### Again, dereplicate all identical sequences after merging.
rule InSilico_derepicate_all:
    conda:
        os.path.join(dir.envs, "vsearch.yml")
    container:
        singularity_envs["vsearch"]
    input:
        "InSilico/1c_derep/merged_all.fasta",
    output:
        "InSilico/2_denoised/dna-sequences.fasta",
    log:
        dir.logs + "/" + "InSilico/1c_all_merged_sequences/dereplicate_all.txt",
    shell:
        """
        vsearch --derep_fulllength {input} \
                --minuniquesize 1 \
                --relabel Seq_ \
                --output {output} \
                2> {log}
        """


### Count the number of occurences of the representative sequences in the samples.


rule InSilico_count_occurences:
    conda:
        os.path.join(dir.envs, "vsearch.yml")
    container:
        singularity_envs["vsearch"]
    input:
        samples="InSilico/1a_trimmed_primers/{sample}_trimmed.fasta",
        rep_seq="InSilico/2_denoised/dna-sequences.fasta",
    output:
        "InSilico/2_denoised/countSeqs/{sample}_count_table.tsv",
    log:
        dir.logs + "/" + "InSilico/2_denoised/countSeqs/{sample}_count_table.tsv",
    shell:
        """       
        if [ -s "{input[samples]}" ]
        then
            echo "{input[samples]} has some data." && \
            vsearch --usearch_global {input[samples]} \
                -otutabout {output} \
                -id 1 \
                -strand plus \
                --db {input[rep_seq]}
                # do something as file has data
        else
            echo "{input[samples]} is empty." && \
            touch {output}
            # do something as file is empty
        fi 2> {log}        
        """


def list_samples_counts(wildcards):
    checkpoint_output = checkpoints.download_assemblies.get(**wildcards).output[0]
    directory = "/".join((checkpoint_output.split("/")[0:2]))
    assemblynames = glob_wildcards(os.path.join(directory, "{i}_genomic.fna.gz")).i
    expd = expand(
        "InSilico/2_denoised/countSeqs/{sample}_count_table.tsv", sample=assemblynames
    )
    return expd


### Format count table from InSilico
rule create_InSilico_count_table:
    conda:
        os.path.join(dir.envs, "amplicons_r_utils.yml")
    container:
        singularity_envs["r_utils"]
    input:
        count_table_samples=list_samples_counts,
    output:
        count_table="InSilico/2_denoised/count_table.tsv",
    log:
        dir.logs + "/" + "InSilico/2_denoised/count_table.tsv",
    script:
        "scripts/create_count_table_from_insilico.R"


### Create a table to compare tax assignment
rule In_silico_tax_compare:
    conda:
        os.path.join(dir.envs, "amplicons_r_utils.yml")
    container:
        singularity_envs["r_utils"]
    input:
        count_table="InSilico/2_denoised/count_table.tsv",
        Metadata_table=community_name + "-assemblies-summary.tsv",
        taxonomy_table="InSilico/3_classified/{classifier}_{tax_DB}/dna-sequences_tax_assignments.txt",
    output:
        output_table="InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax.tsv",
        output_table_long="InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax_long.tsv",
    params:
        viz_replace_empty_tax=REPL_EMPTY,
    log:
        dir.logs
        + "/"
        + "InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax.log",
    script:
        "scripts/In_silico_tax_comparison.R"
