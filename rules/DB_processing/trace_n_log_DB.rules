## Set of rules to backup the input database and generate a hash code of these input files and the output files. 


rule Back_up_master:
    input :
        seqs = config["DBpath_seq"],
        tax = config["DBpath_tax"],
    output :
        seqs = "{prefix}/master/original_seqs.fasta",
        tax = "{prefix}/master/original_tax.txt",
    threads :
        1
    shell :
        '''
        cp {input.seqs} {output.seqs} && \
        cp {input.tax} {output.tax}
        '''


rule Hash_master_files:
    input :
        seqs = "{prefix}/master/original_seqs.fasta",
        tax = "{prefix}/master/original_tax.txt"
    output :
        hash = "{prefix}/master/original.hash",
    threads :
        1
    shell :
        '''
        md5sum {input.seqs} {input.tax} | sort -k 2 | md5sum | cut -f 1 -d " " > {output}
        '''

        
## Generate a hash from all relevant files to insure that we always work with the same reference databases
rule hash_global_DB:
    input:
        master = "{prefix}/master/original.hash",
        QIIME = "{prefix}/QIIME/DB_formatted.hash",
        DADA2 = "{prefix}/dada2rdp/DADA2_DB.hash",
        RDP = "{prefix}/RDP/RDP_DB.hash",
        decipher = "{prefix}/decipher/decipher_DB.hash",
    output:
        trained_tax = "{prefix}/DB.hash",
    threads:
        1
    shell :
        '''
        md5sum {input.master} {input.QIIME} {input.DADA2} {input.RDP} {input.decipher} | sort -k 2 | md5sum | cut -f 1 -d " " > {output}
        '''
