import pandas as pd
import re

### compress as bgz for dicey
rule decompress_recompress:
    conda:
        "../../envs/dicey.yml"
    container:
        singularity_envs["dicey"]
    input:
        "assembly_gz/genomes/{sample}_genomic.fna.gz",
    output:
        "InSilico/PCR/{sample}/{sample}_genomic.fna.gz",
    shell:
        "zcat {input} | bgzip > {output}"


### need some extra files and folder for dicey...
rule dicey_extra_files:
    output:
        repo=directory("InSilico/PCR/dicey"),
    shell:
        """
        wget -P {output.repo} https://github.com/gear-genomics/dicey/archive/refs/tags/v0.3.1.tar.gz 
        tar xzf {output.repo}/*.tar.gz -C {output.repo}
        mv {output.repo}/dicey-*/* {output.repo}/
        """


### In-silico PCR with dicey
rule Extract_amplicon:
    conda:
        "../../envs/dicey.yml"
    container:
        singularity_envs["dicey"]
    input:
        repo="InSilico/PCR/dicey/",
        genome="InSilico/PCR/{sample}/{sample}_genomic.fna.gz",
    output:
        index_genome="InSilico/PCR/{sample}/{sample}_genomic.fna.fm9",
        json="InSilico/PCR/{sample}/dicey_output.json",
        json_gz="InSilico/PCR/{sample}/dicey_output.json.gz",
        amplicons="InSilico/PCR/{sample}/dicey_amplicons.tsv",
    params:
        primers=config["primer_file"],
    threads: 1
    shell:
        """
        dicey index -o {output.index_genome} {input.genome}
        dicey search \
         -i {input.repo}/src/primer3_config \
         -g {input.genome} {params.primers} > {output.json}
        gzip -f -c {output.json} > {output.json_gz}
        python3 {input.repo}/scripts/json2tsv.py -j {output.json_gz} -m amplicon > {output.amplicons}
        """

### extract amplicons into fasta
rule amplicon_fasta:
    conda:
        "../../envs/dicey.yml"
    container:
        singularity_envs["dicey"]
    input:
        json_gz="InSilico/PCR/{sample}/dicey_output.json.gz",
        script=workflow.basedir + "/rules/In_silico/scripts/json2fasta.py",
    output:
        "InSilico/PCR/{sample}/dicey_amplicons.fasta",
    threads: 1
    shell:
        """
        python3 {input.script} {input.json_gz} > {output[0]}
        """
    


### UPDATE VCS: DO NOT USE SAME SCRIPT AS FOR DB; KEEP SEPARATE (IN DB THE FW PRIMER IS NOT ALWAYS PRESENT; IN AMPLICON IT SHOULD)
rule cutadapt_trim_in_silico:
    conda:
        "../../envs/cutadapt.yml"
    container:
        singularity_envs["cutadapt"]
    input:
        R1_raw_reads="InSilico/PCR/{sample}/dicey_amplicons.fasta",
    output:
        R1_trimmed_reads="InSilico/1a_trimmed_primers/{sample}_trimmed.fasta",
    log:
        "InSilico/1a_trimmed_primers/{sample}_trimmed.log",
    params:
        forward_primer=config["forward_primer"],
        reverse_primer=config["reverse_primer"],
        excepted_errors=config["excepted_errors"],
        min_length=config["merged_min_length"],
        max_length=config["merged_max_length"],
        coverage=config["amplicon_min_coverage"],
    threads: 1
    script:
        "scripts/cutadapt_amplicons.py"


def list_amplicons(wildcards):
    checkpoint_output = checkpoints.download_assemblies.get(**wildcards).output[0]
    directory = "/".join((checkpoint_output.split("/")[0:2]))
    assemblynames = glob_wildcards(os.path.join(directory, "{i}_genomic.fna.gz")).i
    expd = expand(
        "InSilico/1a_trimmed_primers/{sample}_trimmed.fasta", sample=assemblynames
    )
    return expd


# primer enlever


### Combine all extracted sequences in one big fasta
rule Insilico_merge_all_in_one_fasta:
    input:
        list_amplicons,
    output:
        "InSilico/1c_derep/merged_all.fasta",
    shell:
        """
        cat {input} >> {output}
        """


### Again, dereplicate all identical sequences after merging.
rule InSilico_derepicate_all:
    conda:
        "../../envs/vsearch.yml"
    container:
        singularity_envs["vsearch"]
    input:
        "InSilico/1c_derep/merged_all.fasta",
    output:
        "InSilico/2_denoised/dna-sequences.fasta",
    log:
        logging_folder + "InSilico/1c_all_merged_sequences/dereplicate_all.txt",
    shell:
        """
        vsearch --derep_fulllength {input} \
                --minuniquesize 1 \
                --relabel Seq_ \
                --output {output} \
                2> {log}
        """


### Count the number of occurences of the representative sequences in the samples.


rule InSilico_count_occurences:
    conda:
        "../../envs/vsearch.yml"
    container:
        singularity_envs["vsearch"]
    input:
        samples="InSilico/1a_trimmed_primers/{sample}_trimmed.fasta",
        rep_seq="InSilico/2_denoised/dna-sequences.fasta",
    output:
        "InSilico/2_denoised/countSeqs/{sample}_count_table.tsv",
    log:
        logging_folder + "InSilico/2_denoised/countSeqs/{sample}_count_table.tsv",
    shell:
        """
        if [ -s "{input[samples]}" ]
        then
            echo "{input[samples]} has some data." && \
            vsearch --usearch_global {input[samples]} \
                -otutabout {output} \
                -id 1 \
                -strand plus \
                --db {input[rep_seq]}
                # do something as file has data
        else
            echo "{input[samples]} is empty." && \
            touch {output}
            # do something as file is empty
        fi 2> {log}
        """


def list_samples_counts(wildcards):
    checkpoint_output = checkpoints.download_assemblies.get(**wildcards).output[0]
    directory = "/".join((checkpoint_output.split("/")[0:2]))
    assemblynames = glob_wildcards(os.path.join(directory, "{i}_genomic.fna.gz")).i
    expd = expand(
        "InSilico/2_denoised/countSeqs/{sample}_count_table.tsv", sample=assemblynames
    )
    return expd


### Format count table from InSilico
rule create_InSilico_count_table:
    conda:
        "../../envs/amplicons_r_utils.yml"
    container:
        singularity_envs["r_utils"]
    input:
        count_table_samples=list_samples_counts,
    output:
        count_table="InSilico/2_denoised/count_table.tsv",
    log:
        logging_folder + "InSilico/2_denoised/count_table.tsv",
    script:
        "scripts/create_count_table_from_insilico.R"


### Create a table to compare tax assignment
rule In_silico_tax_compare:
    conda:
        "../../envs/amplicons_r_utils.yml"
    container:
        singularity_envs["r_utils"]
    input:
        count_table="InSilico/2_denoised/count_table.tsv",
        Metadata_table=community_name + "-assemblies-summary.tsv",
        taxonomy_table="InSilico/3_classified/{classifier}_{tax_DB}/dna-sequences_tax_assignments.txt",
    output:
        output_table="InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax.tsv",
        output_table_long="InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax_long.tsv",
    params:
        viz_replace_empty_tax=config["viz_replace_empty_tax"],
    log:
        logging_folder
        + "InSilico/3_classified/{classifier}_{tax_DB}/InSilico_compare_tax.log",
    script:
        "scripts/In_silico_tax_comparison.R"
